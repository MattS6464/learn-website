---
title: Ecosystemic Interferences
artist: Raw Green Rust
blurb: |
    In this article we look at the improvised performance practice of Raw Green Rust, and how they use the FluCoMa tools to hijack each other’s outputs in Ableton Live and visualise their performance in real time using Unity.
tags: 
    - Max4Live
    - Unity
    - Ableton Live
    - interruption
    - network
    - visualisation
flair: article
featuredimage: /explore/rgr/unisson_example_1.png
author: Jacob
---

<script>
    import Image from '$lib/components/Image.svelte';
    import YouTube from '$lib/components/YouTube.svelte';
    import ArtistCard from '$lib/components/mwf/ArtistCard.svelte';
    import CodeBlock from '$lib/components/CodeBlock.svelte';
    import ExploreDownload from '$lib/components/ExploreDownload.svelte';
</script>

<style>
    .artist-cards {
        display: flex;
        flex-direction: row;
        flex-wrap: wrap;
    }
</style>

<div class="artist-cards">
    <ArtistCard
    src = "/explore/eldridge/alice-profile.jpeg"
    name = "Alice Eldridge"
    website = "https://profiles.sussex.ac.uk/p127749-alice-eldridge"
    >
    <p slot="bio">
    Alice Eldridge is a musician, researcher and Lecturer working at the interstices of music, technology & ecology. Described as a voluntary hybrid appeared she is recognised internationally both for her contributions to creative technology and new music research and the emerging science of ecoacoustics. As a soundscape ecologist she has featured on BBC TV Spring Watch and BBC Radio 4 Costing the Earth; as a cellist she has made numerous appearances on BBC Radio 3 Late Junction and Jazz on 3. Her contemporary chamber compositions have been broadcast on BBC Radio 6 Freak Zone, and she has appeared on BBC Radio 1 John Peel Show as a pop bassist.
    </p>
    </ArtistCard>
    <ArtistCard
    src = "/explore/eldridge/chris-profile.jpeg"
    name = "Chris Kiefer"
    website = "https://profiles.sussex.ac.uk/p208667-chris-kiefer"
    >
    <p slot="bio">
    Chris Kiefer is a computer-musician and musical instrument designer, specialising in musician-computer interaction, physical computing, and machine learning. He performs with custom-made instruments including malleable foam interfaces, touch screen software, interactive sculptures and a modified self-resonating cello. Chris’ research often focuses on participatory design and development of interactive music systems in everyday settings, including digital instruments for children with disabilities, and development of the NETEM networked score system for musical ensembles. His work also concentrates on machine learning and signal processing for audio and interaction, with an emphasis on nonlinear and dynamical systems.
    </p>
    </ArtistCard>
</div>

## Introduction

<ExploreDownload
url={'/explore/eldridge/Alice Eldridge and Chris Kiefer Examples.zip'}
/>

Today we’ll be looking at some of the work that Alice Eldridge and Chris Kiefer did using the FluCoMa tools. These two collaborators came to the project seeking to augment their already well-established feedback instrument, the [Feedback Cello](https://www.feedbackcell.info/). We shall see how they used machine learning and descriptors to create a shared, adaptive instrument which takes improvisation to the next level , and how they approached this system in performance. As with all the "[Explore](/explore)" articles, there is a series of demonstration patches that can be <a href='https://f003.backblazeb2.com/file/learnassets/explore/eldridge/Alice+Eldridge+and+Chris Kiefer+Examples.zip' download='Alice Eldridge and Chris Kiefer Examples.zip'>downloaded</a> and interacted with if you wish to explore the inner workings of the software.